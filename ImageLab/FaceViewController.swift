//
//  FaceViewController.swift
//  ImageLab
//
//  Created by Kevin Queenan on 10/12/17.
//  Copyright Â© 2017 Eric Larson. All rights reserved.
//

import UIKit
import AVFoundation

class FaceViewController: UIViewController {
    var videoManager : VideoAnalgesic! = nil
    
    let faceFilter : CIFilter = CIFilter(name: "CISmoothLinearGradient")!
    let eyeFilter : CIFilter = CIFilter(name: "CISmoothLinearGradient")!
    let mouthFilter : CIFilter = CIFilter(name: "CISmoothLinearGradient")!
    
    @IBOutlet weak var numberOfFaces: UILabel!
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        self.view.backgroundColor = nil
        
        self.videoManager = VideoAnalgesic.sharedInstance
        
        self.videoManager.setCameraPosition(position: AVCaptureDevice.Position.front)
        
        self.videoManager.setProcessingBlock(newProcessBlock: self.processFaces)
        
        if !self.videoManager.isRunning{
            self.videoManager.start()
        }
    }

    func processFaces(inputImage:CIImage) -> CIImage{
        // setting up CIColors to use in conjunction with CIFilters
        // UIColor -> CIColor
        let uiRed : UIColor = UIColor.red
        let uiBlue : UIColor = UIColor.blue
        let uiGreen : UIColor = UIColor.green
        let faceColor : CIColor = CIColor(color: uiRed)
        let eyeColor : CIColor = CIColor(color: uiBlue)
        let mouthColor : CIColor = CIColor(color: uiGreen)
        self.faceFilter.setValue(faceColor, forKey: "inputColor1")
        self.eyeFilter.setValue(eyeColor, forKey: "inputColor1")
        self.mouthFilter.setValue(mouthColor, forKey: "inputColor1")
        
        // from Larson's slides
        let optsDetector = [CIDetectorAccuracy:CIDetectorAccuracyHigh]
        let detector = CIDetector(ofType: CIDetectorTypeFace, context: self.videoManager.getCIContext(), options: optsDetector)
        
        // added smile & blink detection
        var optsFace = [CIDetectorImageOrientation:self.videoManager.getImageOrientationFromUIOrientation(UIApplication.shared.statusBarOrientation), CIDetectorSmile:true, CIDetectorEyeBlink:true] as [String : Any]

        var features = detector?.features(in: inputImage, options: optsFace)
        var swap = CGPoint()
        var buffer = inputImage
        
        // if no faces detected
        if features?.count == 0{
            DispatchQueue.main.async{
                self.numberOfFaces.text = "No Faces Found"
            }
        }
        else if features?.count == 1{
            let face : CIFaceFeature = features![0] as! CIFaceFeature
            var faceDetails = ""
            if face.hasSmile{
                faceDetails += "Smile "
            }
            else{
                faceDetails += "No Smile "
            }
            if face.leftEyeClosed{
                faceDetails += "Left Eye Closed "
            }
            else{
                faceDetails += "Left Eye Open "
            }
            if face.rightEyeClosed{
                faceDetails += "Right Eye Closed"
            }
            else{
                faceDetails += "Right Eye Open"
            }
            DispatchQueue.main.async{
                self.numberOfFaces.text = faceDetails
            }
        }
        else{
            DispatchQueue.main.async{
                let count = features?.count
                self.numberOfFaces.text = "\(count)"
            }
        }
        
        for face in features as! [CIFaceFeature]{
            
        }
        return buffer
    }
    
    override func viewDidDisappear(_ animated: Bool) {
        if(self.videoManager.isRunning){
            self.videoManager.turnOffFlash()
            self.videoManager.stop()
            self.videoManager.shutdown()
        }
    }
    
    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        
    }

}
